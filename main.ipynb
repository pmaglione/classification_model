{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import beta\n",
    "import collections\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "def binomial_likelihood(p, n, y):\n",
    "    return (math.factorial(n) / (math.factorial(y) * math.factorial(n - y))) * math.pow(p, y) * math.pow(1 - p, n - y)\n",
    "    \n",
    "\n",
    "def get_workers_accuracy(acc):\n",
    "    return sum(acc) / len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Workers:\n",
    "\n",
    "    def __init__(self, workers_num, cheaters_prop, fixed_acc = False, workers_acc = .5):\n",
    "        self.workers_num = workers_num\n",
    "        self.cheaters_prop = cheaters_prop\n",
    "        self.acc_passed = []\n",
    "        self.fixed_acc = fixed_acc\n",
    "        self.workers_acc = workers_acc\n",
    "\n",
    "    # simulate workers\n",
    "    def simulate_workers(self):\n",
    "        for _ in range(self.workers_num):\n",
    "            if (self.fixed_acc == False):\n",
    "                if np.random.binomial(1, self.cheaters_prop):\n",
    "                    # worker_type is 'rand_ch'\n",
    "                    worker_acc_pos = 0.5\n",
    "                else:\n",
    "                    # worker_type is 'worker'\n",
    "                    worker_acc_pos = 0.8 + (np.random.beta(1, 1) * 0.2)\n",
    "            else:\n",
    "                worker_acc_pos = self.workers_acc\n",
    "            \n",
    "            self.acc_passed.append(worker_acc_pos)\n",
    "        #end for\n",
    "            \n",
    "        return self.acc_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classificator:\n",
    "    def classification_fn_posterior(votes, prior, accuracy):    \n",
    "        n = len(votes)\n",
    "        y = sum(votes.values())\n",
    "\n",
    "        likelihood = binomial_likelihood(prior, n, y)\n",
    "\n",
    "        #bayes theorem\n",
    "        posterior = (likelihood * prior) / ((likelihood * prior) + (1 - accuracy) * (1 - prior))\n",
    "\n",
    "        return posterior\n",
    "    \n",
    "    def classification_fn_beta_pdf(votes, th, accuracy):    \n",
    "        n = len(votes)\n",
    "        y = sum(votes.values())\n",
    "\n",
    "        posterior = beta.sf(th, 1 + y, 1 + (n - y))\n",
    "\n",
    "        return posterior\n",
    "    \n",
    "    def classification_fn_mv(votes):\n",
    "        n = len(votes)\n",
    "        s = sum(votes.values())\n",
    "\n",
    "        return sum(votes.values()) / len(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_metrics(items, gt, lr):\n",
    "        # obtain ground_truth scope values for items\n",
    "\n",
    "        #fp = false inclusion\n",
    "        #fn = false exlusion\n",
    "        fp = fn = tp = tn = 0. \n",
    "\n",
    "        for cl_val, gt_val in zip(items, gt):\n",
    "            if gt_val and not cl_val:\n",
    "                fp += 1\n",
    "            if not gt_val and cl_val:\n",
    "                fn += 1\n",
    "            if gt_val and cl_val:\n",
    "                tn += 1\n",
    "            if not gt_val and not cl_val:\n",
    "                tp += 1\n",
    "\n",
    "        recall = tp / (tp + fn)\n",
    "        precision = tp / (tp + fp)\n",
    "        loss = (fp + fn) / len(items)\n",
    "\n",
    "        return loss,  recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "\n",
    "    def __init__(self, params):\n",
    "        self.workers_accuracy = params['workers_accuracy']\n",
    "        self.workers_num = params['workers_num']      \n",
    "        self.items_num = params['items_num']      \n",
    "        self.cost_ratio = params.get('cost_ratio')\n",
    "        self.classification_threshold = params.get('classification_threshold')\n",
    "        self.index_workers_voted_on_item = {}\n",
    "        self.votes_per_item = params['votes_per_item']\n",
    "    \n",
    "    def generate_gold_data(self, items_num, true_percentage):\n",
    "        gold_data = []\n",
    "        for item_index in range(items_num):\n",
    "            if np.random.binomial(1, true_percentage):\n",
    "                val = 1\n",
    "            else:\n",
    "                val = 0\n",
    "            gold_data.append(val)\n",
    "        #end for\n",
    "        return gold_data\n",
    "    \n",
    "    def get_random_worker_accuracy(self, item, items_num):       \n",
    "        '''\n",
    "        #TO-DO: add logic to avoid worker vote on same task\n",
    "        worker_found = False\n",
    "        \n",
    "        while (worker_found == False):\n",
    "            index = np.random.randn(0, self.workers_num - 1)\n",
    "\n",
    "            if (index not in self.index_workers_voted_on_item[item]):\n",
    "                self.index_workers_voted_on_item[item].append(index)\n",
    "                worker_found = True\n",
    "        ''' \n",
    "        worker_id = random.randint(0, self.workers_num - 1)\n",
    "        return (worker_id, self.workers_accuracy[worker_id])\n",
    "    \n",
    "    def get_worker_vote(self, i, items_num):\n",
    "        worker_id, worker_acc = self.get_random_worker_accuracy(i, items_num)\n",
    "        \n",
    "        if np.random.binomial(1, worker_acc):\n",
    "            vote = 1\n",
    "        else:\n",
    "            vote = 0\n",
    "            \n",
    "        return (worker_id, vote)\n",
    "    \n",
    "    def get_items_predicted_classified(results):\n",
    "        return {i:v for (i,v) in results.items() if v['decision'] == True}\n",
    "    \n",
    "    def generate_votes_gt(self, items_num):\n",
    "        total_votes = collections.defaultdict(dict)\n",
    "        \n",
    "        #base votes\n",
    "        for i in range(items_num):\n",
    "            for k in range(self.votes_per_item):\n",
    "                worker_id, vote = self.get_worker_vote(i, items_num)\n",
    "\n",
    "                total_votes[i][worker_id] = vote\n",
    "\n",
    "        #evaluate votes\n",
    "        results = Evaluator.decision_fn(items_num, total_votes, self.classification_threshold, self.cost_ratio, \n",
    "                                                       Classificator.classification_fn_mv) \n",
    "        #Check if must continue collecting votes\n",
    "        items_predicted_classified = Generator.get_items_predicted_classified(results)\n",
    "        must_get_more_votes = len(items_predicted_classified) > 0\n",
    "        \n",
    "        while(must_get_more_votes):\n",
    "            for i, v in items_predicted_classified.items():\n",
    "                worker_id, vote = self.get_worker_vote(i, items_num)\n",
    "\n",
    "                total_votes[i][worker_id] = vote\n",
    "\n",
    "                results = Evaluator.decision_fn(items_num, total_votes, self.classification_threshold, self.cost_ratio, \n",
    "                                                       Classificator.classification_fn_mv)\n",
    "            #end for\n",
    "            \n",
    "            #Stop when there are no more items that can be classified\n",
    "            items_predicted_classified = Generator.get_items_predicted_classified(results)\n",
    "            must_get_more_votes = len(items_predicted_classified) > 0\n",
    "        #end while \n",
    "        \n",
    "        items_classified_in = len([x for (x,v) in results.items() if v['decision'] == False and v['confidence'] > ct])\n",
    "        items_predicted_classified_in = len([x for (x,v) in results.items() if v['decision'] == True])\n",
    "        items_classified_out = len([x for (x,v) in results.items() if v['decision'] == False and v['confidence'] <= ct])    \n",
    "            \n",
    "        return {\n",
    "                'votes': total_votes, \n",
    "                'items_classified_in': items_classified_in,\n",
    "                'items_predicted_classified_in': items_predicted_classified_in,\n",
    "                'items_classified_out' : items_classified_out\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    '''\n",
    "    Function to answer: must continue collecting votes over each task?\n",
    "\n",
    "    Input:\n",
    "        items_num - amount if items\n",
    "        votes - dictionary of dictionaries, containing the votes over each item where keys corresponds to workers ID\n",
    "            {\n",
    "                item_i: {worker_i:vote...worker_n:vote},\n",
    "                ...\n",
    "                item_n: {worker_i:vote...worker_n:vote},\n",
    "            }\n",
    "        classification_threshold - value between 0 and 1 for deciding if prob of data is enough or must continue\n",
    "        cost_ratio - ratio of crowd to expert cost, value between 0 and 1\n",
    "        classification_function - function to calculate how likely is to be classified\n",
    "        \n",
    "    Output:\n",
    "        Dictionary with the decision indexed by item_id\n",
    "            {\n",
    "                item_id: {'decision': bool, 'confidence': % of confidence)\n",
    "                ...\n",
    "                item_n: ...\n",
    "            }\n",
    "    '''\n",
    "    def decision_fn(items_num, votes, classification_threshold, cost_ratio, classification_function):\n",
    "          \n",
    "        items_decision = dict.fromkeys(range(items_num), True) #True means isnt classified and isnt too expensive        \n",
    "        expert_cost = 1 / cost_ratio  \n",
    "\n",
    "        results = dict.fromkeys(range(items_num), {'decision': False, 'confidence': 0, 'votes': {}})\n",
    "        \n",
    "        #TO-DO: increment expert_cost * N\n",
    "        for item_id, item_state in items_decision.items():            \n",
    "            item_predicted_votes = votes[item_id].copy()\n",
    "            actual_cost = len(item_predicted_votes) #actual cost per item i\n",
    "            \n",
    "            #while: item not classified or not too expensive\n",
    "            while (items_decision[item_id] == True):\n",
    "                \n",
    "                #prob with actual votes\n",
    "                classification_prob = classification_function(item_predicted_votes) #mv\n",
    "                \n",
    "                if classification_prob > classification_threshold:\n",
    "                    items_decision[item_id] = False\n",
    "                    if (len(item_predicted_votes) == len(votes[item_id])):\n",
    "                        #if is already classified: stop collecting\n",
    "                        results[item_id] = {'decision': False, 'confidence': classification_prob}\n",
    "                    else:\n",
    "                        #if predictions give that can be classified: continue collecting\n",
    "                        results[item_id] = {'decision': True, 'confidence': classification_prob}\n",
    "                else:\n",
    "                    #draw vote\n",
    "                    vote = np.random.binomial(1, classification_prob)\n",
    "                    new_index = max(item_predicted_votes.keys()) + 1\n",
    "                    item_predicted_votes[new_index] = vote\n",
    "                    actual_cost += 1 #increment actual cost with each simulated vote \n",
    "                    if(actual_cost >= expert_cost):\n",
    "                        #Set false if the item is too expensive\n",
    "                        items_decision[item_id] = False\n",
    "                        results[item_id] = {'decision': False, 'confidence': classification_prob}\n",
    "            #end while    \n",
    "        #end for              \n",
    "                \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:04<00:23,  4.70s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:15<00:26,  6.60s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [00:54<00:48, 16.18s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [02:15<01:11, 35.68s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [06:10<01:35, 95.41s/it]\u001b[A\n",
      "100%|██████████| 6/6 [10:11<00:00, 139.20s/it]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations per ct: 100\n",
      "Items: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Crowd Avg</th>\n",
       "      <th>Expert Avg</th>\n",
       "      <th>Cost Avg</th>\n",
       "      <th>Cost Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.70</td>\n",
       "      <td>96.38</td>\n",
       "      <td>3.62</td>\n",
       "      <td>10.7884</td>\n",
       "      <td>0.363364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>94.84</td>\n",
       "      <td>5.16</td>\n",
       "      <td>11.4990</td>\n",
       "      <td>0.680902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.80</td>\n",
       "      <td>91.34</td>\n",
       "      <td>8.66</td>\n",
       "      <td>13.6242</td>\n",
       "      <td>1.115323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.85</td>\n",
       "      <td>84.54</td>\n",
       "      <td>15.46</td>\n",
       "      <td>15.4838</td>\n",
       "      <td>1.693108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>67.02</td>\n",
       "      <td>32.98</td>\n",
       "      <td>19.3630</td>\n",
       "      <td>2.306452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.95</td>\n",
       "      <td>49.63</td>\n",
       "      <td>50.37</td>\n",
       "      <td>16.2496</td>\n",
       "      <td>1.312514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold  Crowd Avg  Expert Avg  Cost Avg  Cost Std\n",
       "0       0.70      96.38        3.62   10.7884  0.363364\n",
       "1       0.75      94.84        5.16   11.4990  0.680902\n",
       "2       0.80      91.34        8.66   13.6242  1.115323\n",
       "3       0.85      84.54       15.46   15.4838  1.693108\n",
       "4       0.90      67.02       32.98   19.3630  2.306452\n",
       "5       0.95      49.63       50.37   16.2496  1.312514"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assumptions\n",
    "#1 condition\n",
    "#difficulty of tasks are all equal\n",
    "#there are no test questions\n",
    "#there are a percent of cheaters\n",
    "\n",
    "items_num = 100\n",
    "cts = np.arange(.7, .96, 0.05) #classification thresholds\n",
    "cr = .02 #ratio 1:100\n",
    "iter_num = 100\n",
    "workers_num = 1000\n",
    "votes_per_item = 5\n",
    "fixed_acc = False\n",
    "workers_acc = .9\n",
    "true_percentage = 1\n",
    "\n",
    "main_results = []\n",
    "\n",
    "for ct in tqdm(cts):\n",
    "    ct = round(ct, 2) #limit to two decimals\n",
    "    cost = []\n",
    "    items_classified_in = []\n",
    "    items_classified_out = []\n",
    "    \n",
    "    for _ in range(iter_num):\n",
    "        workers_accuracy = Workers(workers_num, z, fixed_acc, workers_acc).simulate_workers()\n",
    "\n",
    "        params = {\n",
    "            'workers_accuracy': workers_accuracy,\n",
    "            'workers_num': workers_num,\n",
    "            'items_num': items_num,\n",
    "            'cost_ratio': cr,\n",
    "            'classification_threshold': ct,\n",
    "            'votes_per_item': votes_per_item,\n",
    "            \n",
    "        }\n",
    "\n",
    "        ground_truth = Generator(params).generate_gold_data(items_num, true_percentage)\n",
    "\n",
    "        th_results = Generator(params).generate_votes_gt(items_num)\n",
    "\n",
    "        cost.append(sum([len(v) for (x,v) in th_results['votes'].items()]) * cr)\n",
    "        items_classified_in.append(th_results['items_classified_in'])\n",
    "        items_classified_out.append(th_results['items_classified_out'])\n",
    "    #end for iterations\n",
    "    \n",
    "    main_results.append([ct, np.mean(items_classified_in), np.mean(items_classified_out), np.mean(cost), np.std(cost)])\n",
    "#end for thresholds\n",
    "\n",
    "print(\"Iterations per ct: {}\".format(iter_num))\n",
    "print(\"Items: {}\".format(items_num))\n",
    "pd.DataFrame(main_results, columns=[\"Threshold\",\"Crowd Avg\", \"Expert Avg\",\"Cost Avg\",\"Cost Std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
