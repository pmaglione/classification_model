{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import beta\n",
    "import collections\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "def binomial_likelihood(p, n, y):\n",
    "    return (math.factorial(n) / (math.factorial(y) * math.factorial(n - y))) * math.pow(p, y) * math.pow(1 - p, n - y)\n",
    "    \n",
    "\n",
    "def get_workers_accuracy(acc):\n",
    "    return sum(acc) / len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Workers:\n",
    "\n",
    "    def __init__(self, workers_num, cheaters_prop, fixed_acc = False, workers_acc = .5):\n",
    "        self.workers_num = workers_num\n",
    "        self.cheaters_prop = cheaters_prop\n",
    "        self.acc_passed = []\n",
    "        self.fixed_acc = fixed_acc\n",
    "        self.workers_acc = workers_acc\n",
    "\n",
    "    # simulate workers\n",
    "    def simulate_workers(self):\n",
    "        for _ in range(self.workers_num):\n",
    "            if (self.fixed_acc == False):\n",
    "                if np.random.binomial(1, self.cheaters_prop):\n",
    "                    # worker_type is 'rand_ch'\n",
    "                    worker_acc_pos = 0.5\n",
    "                else:\n",
    "                    # worker_type is 'worker'\n",
    "                    worker_acc_pos = 0.8 + (np.random.beta(1, 1) * 0.2)\n",
    "            else:\n",
    "                worker_acc_pos = self.workers_acc\n",
    "            \n",
    "            self.acc_passed.append(worker_acc_pos)\n",
    "        #end for\n",
    "            \n",
    "        return self.acc_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classificator:\n",
    "    def classification_fn_posterior(votes, prior, accuracy):    \n",
    "        n = len(votes)\n",
    "        y = sum(votes.values())\n",
    "\n",
    "        likelihood = binomial_likelihood(prior, n, y)\n",
    "\n",
    "        #bayes theorem\n",
    "        posterior = (likelihood * prior) / ((likelihood * prior) + (1 - accuracy) * (1 - prior))\n",
    "\n",
    "        return posterior\n",
    "    \n",
    "    def classification_fn_beta_pdf(votes, th, accuracy):    \n",
    "        n = len(votes)\n",
    "        y = sum(votes.values())\n",
    "\n",
    "        posterior = beta.sf(th, 1 + y, 1 + (n - y))\n",
    "\n",
    "        return posterior\n",
    "    \n",
    "    def classification_fn_mv(votes):\n",
    "        n = len(votes)\n",
    "        s = sum(votes.values())\n",
    "\n",
    "        return sum(votes.values()) / len(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_metrics(items, gt, lr):\n",
    "        # obtain ground_truth scope values for items\n",
    "\n",
    "        #fp = false inclusion\n",
    "        #fn = false exlusion\n",
    "        fp = fn = tp = tn = 0. \n",
    "\n",
    "        for cl_val, gt_val in zip(items, gt):\n",
    "            if gt_val and not cl_val:\n",
    "                fp += 1\n",
    "            if not gt_val and cl_val:\n",
    "                fn += 1\n",
    "            if gt_val and cl_val:\n",
    "                tn += 1\n",
    "            if not gt_val and not cl_val:\n",
    "                tp += 1\n",
    "\n",
    "        recall = tp / (tp + fn)\n",
    "        precision = tp / (tp + fp)\n",
    "        loss = (fp + fn) / len(items)\n",
    "\n",
    "        return loss,  recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "\n",
    "    def __init__(self, params):\n",
    "        self.workers_accuracy = params['workers_accuracy']\n",
    "        self.workers_num = params['workers_num']      \n",
    "        self.items_num = params['items_num']      \n",
    "        self.cost_ratio = params.get('cost_ratio')\n",
    "        self.classification_threshold = params.get('classification_threshold')\n",
    "        self.index_workers_voted_on_item = {}\n",
    "        self.votes_per_item = params['votes_per_item']\n",
    "    \n",
    "    def generate_gold_data(self, items_num, true_percentage):\n",
    "        gold_data = []\n",
    "        for item_index in range(items_num):\n",
    "            if np.random.binomial(1, true_percentage):\n",
    "                val = 1\n",
    "            else:\n",
    "                val = 0\n",
    "            gold_data.append(val)\n",
    "        #end for\n",
    "        return gold_data\n",
    "    \n",
    "    def get_random_worker_accuracy(self, item, items_num):       \n",
    "        '''\n",
    "        #TO-DO: add logic to avoid worker vote on same task\n",
    "        worker_found = False\n",
    "        \n",
    "        while (worker_found == False):\n",
    "            index = np.random.randn(0, self.workers_num - 1)\n",
    "\n",
    "            if (index not in self.index_workers_voted_on_item[item]):\n",
    "                self.index_workers_voted_on_item[item].append(index)\n",
    "                worker_found = True\n",
    "        ''' \n",
    "        worker_id = random.randint(0, self.workers_num - 1)\n",
    "        return (worker_id, self.workers_accuracy[worker_id])\n",
    "    \n",
    "    def get_worker_vote(self, i, items_num):\n",
    "        worker_id, worker_acc = self.get_random_worker_accuracy(i, items_num)\n",
    "        \n",
    "        if np.random.binomial(1, worker_acc):\n",
    "            vote = 1\n",
    "        else:\n",
    "            vote = 0\n",
    "            \n",
    "        return (worker_id, vote)\n",
    "    \n",
    "    def get_items_predicted_classified(results):\n",
    "        return {i:v for (i,v) in results.items() if v['decision'] == True}\n",
    "    \n",
    "    def generate_votes_gt(self, items_num):\n",
    "        total_votes = collections.defaultdict(dict)\n",
    "        \n",
    "        #base votes\n",
    "        for i in range(items_num):\n",
    "            for k in range(self.votes_per_item):\n",
    "                worker_id, vote = self.get_worker_vote(i, items_num)\n",
    "\n",
    "                total_votes[i][worker_id] = vote\n",
    "\n",
    "        #evaluate votes\n",
    "        results = Evaluator.decision_fn(items_num, total_votes, self.classification_threshold, self.cost_ratio, \n",
    "                                                       Classificator.classification_fn_mv) \n",
    "        #Check if must continue collecting votes\n",
    "        items_predicted_classified = Generator.get_items_predicted_classified(results)\n",
    "        must_get_more_votes = len(items_predicted_classified) > 0\n",
    "        \n",
    "        while(must_get_more_votes):\n",
    "            for i, v in items_predicted_classified.items():\n",
    "                worker_id, vote = self.get_worker_vote(i, items_num)\n",
    "\n",
    "                total_votes[i][worker_id] = vote                \n",
    "            #end for\n",
    "            results = Evaluator.decision_fn(items_num, total_votes, self.classification_threshold, self.cost_ratio, \n",
    "                                                       Classificator.classification_fn_mv)\n",
    "            \n",
    "            #Stop when there are no more items that can be classified\n",
    "            items_predicted_classified = Generator.get_items_predicted_classified(results)\n",
    "            must_get_more_votes = len(items_predicted_classified) > 0\n",
    "        #end while \n",
    "        \n",
    "        items_classified_in = len([x for (x,v) in results.items() if v['decision'] == False and v['confidence'] > ct])\n",
    "        items_predicted_classified_in = len([x for (x,v) in results.items() if v['decision'] == True])\n",
    "        items_classified_out = len([x for (x,v) in results.items() if v['decision'] == False and v['confidence'] <= ct])    \n",
    "            \n",
    "        return {\n",
    "                'votes': total_votes, \n",
    "                'items_classified_in': items_classified_in,\n",
    "                'items_predicted_classified_in': items_predicted_classified_in,\n",
    "                'items_classified_out' : items_classified_out\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    '''\n",
    "    Function to answer: must continue collecting votes over each task?\n",
    "\n",
    "    Input:\n",
    "        items_num - amount if items\n",
    "        votes - dictionary of dictionaries, containing the votes over each item where keys corresponds to workers ID\n",
    "            {\n",
    "                item_i: {worker_i:vote...worker_n:vote},\n",
    "                ...\n",
    "                item_n: {worker_i:vote...worker_n:vote},\n",
    "            }\n",
    "        classification_threshold - value between 0 and 1 for deciding if prob of data is enough or must continue\n",
    "        cost_ratio - ratio of crowd to expert cost, value between 0 and 1\n",
    "        classification_function - function to calculate how likely is to be classified\n",
    "        \n",
    "    Output:\n",
    "        Dictionary with the decision indexed by item_id\n",
    "            {\n",
    "                item_id: {'decision': bool, 'confidence': % of confidence)\n",
    "                ...\n",
    "                item_n: ...\n",
    "            }\n",
    "    '''\n",
    "    def decision_fn(items_num, votes, classification_threshold, cost_ratio, classification_function):\n",
    "          \n",
    "        items_decision = dict.fromkeys(range(items_num), True) #True means isnt classified and isnt too expensive        \n",
    "        expert_cost = 1 / cost_ratio  \n",
    "\n",
    "        results = dict.fromkeys(range(items_num), {'decision': False, 'confidence': 0, 'votes': {}})\n",
    "        \n",
    "        #TO-DO: increment expert_cost * N\n",
    "        for item_id, item_state in items_decision.items():            \n",
    "            item_predicted_votes = votes[item_id].copy()\n",
    "            actual_cost = len(item_predicted_votes) #actual cost per item i\n",
    "            must_continue = True\n",
    "            #while: item not classified or not too expensive\n",
    "            while (must_continue == True):\n",
    "                \n",
    "                #prob with actual votes\n",
    "                classification_prob = classification_function(item_predicted_votes) #mv\n",
    "                \n",
    "                if classification_prob > classification_threshold:\n",
    "                    must_continue = False\n",
    "                    if (len(item_predicted_votes) == len(votes[item_id])):\n",
    "                        #if is already classified: stop collecting\n",
    "                        results[item_id] = {'decision': False, 'confidence': classification_prob}\n",
    "                    else:\n",
    "                        #if predictions give that can be classified: continue collecting\n",
    "                        results[item_id] = {'decision': True, 'confidence': classification_prob}\n",
    "                else:\n",
    "                    #draw vote\n",
    "                    vote = np.random.binomial(1, classification_prob)\n",
    "                    new_index = max(item_predicted_votes.keys()) + 1\n",
    "                    item_predicted_votes[new_index] = vote\n",
    "                    actual_cost += 1 #increment actual cost with each simulated vote \n",
    "                    if(actual_cost >= expert_cost):\n",
    "                        #Set false if the item is too expensive\n",
    "                        must_continue = False\n",
    "                        results[item_id] = {'decision': False, 'confidence': classification_prob}\n",
    "            #end while    \n",
    "        #end for              \n",
    "                \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 1/6 [00:09<00:45,  9.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 2/6 [00:31<00:53, 13.25s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 3/6 [01:19<01:10, 23.59s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 4/6 [02:37<01:19, 39.92s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 5/6 [04:22<00:59, 59.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 6/6 [05:44<00:00, 66.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations per ct: 100\n",
      "Items: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Cost Avg</th>\n",
       "      <th>Cost Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.70</td>\n",
       "      <td>4.1839</td>\n",
       "      <td>0.378629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>5.5395</td>\n",
       "      <td>0.777514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.80</td>\n",
       "      <td>6.9300</td>\n",
       "      <td>1.185569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.85</td>\n",
       "      <td>7.4130</td>\n",
       "      <td>1.508260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>7.1950</td>\n",
       "      <td>1.446722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.95</td>\n",
       "      <td>5.3173</td>\n",
       "      <td>0.667646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold  Cost Avg  Cost Std\n",
       "0       0.70    4.1839  0.378629\n",
       "1       0.75    5.5395  0.777514\n",
       "2       0.80    6.9300  1.185569\n",
       "3       0.85    7.4130  1.508260\n",
       "4       0.90    7.1950  1.446722\n",
       "5       0.95    5.3173  0.667646"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assumptions\n",
    "#1 condition\n",
    "#difficulty of tasks are all equal\n",
    "#there are no test questions\n",
    "#there are a percent of cheaters\n",
    "\n",
    "items_num = 100\n",
    "cts = np.arange(.7, .96, 0.05) #classification thresholds\n",
    "cr = .01 #ratio 1:100\n",
    "iter_num = 100\n",
    "workers_num = 1000\n",
    "votes_per_item = 3\n",
    "fixed_acc = True\n",
    "workers_acc = .80\n",
    "true_percentage = 1\n",
    "\n",
    "main_results = []\n",
    "\n",
    "for ct in tqdm(cts):\n",
    "    ct = round(ct, 2) #limit to two decimals\n",
    "    cost = []\n",
    "    items_classified_in = []\n",
    "    items_classified_out = []\n",
    "    \n",
    "    for _ in range(iter_num):\n",
    "        workers_accuracy = Workers(workers_num, z, fixed_acc, workers_acc).simulate_workers()\n",
    "\n",
    "        params = {\n",
    "            'workers_accuracy': workers_accuracy,\n",
    "            'workers_num': workers_num,\n",
    "            'items_num': items_num,\n",
    "            'cost_ratio': cr,\n",
    "            'classification_threshold': ct,\n",
    "            'votes_per_item': votes_per_item,\n",
    "            \n",
    "        }\n",
    "\n",
    "        ground_truth = Generator(params).generate_gold_data(items_num, true_percentage)\n",
    "\n",
    "        th_results = Generator(params).generate_votes_gt(items_num)\n",
    "\n",
    "        cost.append(sum([len(v) for (x,v) in th_results['votes'].items()]) * cr)\n",
    "        items_classified_in.append(th_results['items_classified_in'])\n",
    "        items_classified_out.append(th_results['items_classified_out'])\n",
    "    #end for iterations\n",
    "    \n",
    "    main_results.append([ct, np.mean(cost), np.std(cost)])\n",
    "#end for thresholds\n",
    "\n",
    "print(\"Iterations per ct: {}\".format(iter_num))\n",
    "print(\"Items: {}\".format(items_num))\n",
    "pd.DataFrame(main_results, columns=[\"Threshold\",\"Cost Avg\",\"Cost Std\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
